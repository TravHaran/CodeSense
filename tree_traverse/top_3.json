{
    "results": [
        {
            "score": 0.8333333333333334,
            "matched_keywords": [
                "python",
                "function",
                "nltk",
                "extract_keywords",
                "word2vec"
            ],
            "node": {
                "name": "main.py",
                "type": "file",
                "keywords": [
                    "*",
                    "Comparison",
                    "Embeddings",
                    "Extraction",
                    "Gensim",
                    "Keyword",
                    "NLP",
                    "NLTK",
                    "Processing",
                    "Python",
                    "Similarity",
                    "Text",
                    "Word",
                    "Word2Vec",
                    "calculates",
                    "code",
                    "compare_keywords",
                    "compare_words",
                    "comparing",
                    "computes",
                    "console",
                    "context",
                    "create",
                    "embeddings",
                    "employs",
                    "extract_keywords",
                    "extracted",
                    "extraction",
                    "extracts",
                    "file",
                    "focuses",
                    "function",
                    "input",
                    "keyword",
                    "keywords",
                    "keywords.The",
                    "language",
                    "libraries",
                    "library",
                    "list",
                    "lists",
                    "model",
                    "modeling.1",
                    "output",
                    "performs",
                    "processes",
                    "processing",
                    "reads",
                    "removes",
                    "returned",
                    "score",
                    "sentences",
                    "similarity",
                    "tagging",
                    "techniques",
                    "text",
                    "texts",
                    "tokenizes",
                    "uses",
                    "using",
                    "vector",
                    "verbs",
                    "word",
                    "words",
                    "words.3",
                    "written"
                ],
                "annotation": "The code is written in Python and focuses on keyword extraction from text and comparing the similarity between keyword lists using natural language processing (NLP) techniques. It employs the NLTK and Gensim libraries for text processing and word vector modeling.\n\n1. **Keyword Extraction**: The function `extract_keywords` tokenizes input text, removes stop words, performs part-of-speech tagging, and extracts significant words (nouns and verbs). These extracted keywords are then returned as a list.\n   \n2. **Text Processing and Word Embeddings**: The code reads and processes a context file, tokenizes the sentences into words, and uses the Gensim library's Word2Vec model to create word embeddings for these words.\n\n3. **Similarity Comparison**: With the `compare_words` function, the code computes the similarity between two words using the Word2Vec model, and `compare_keywords` function calculates the cumulative similarity score between two lists of keywords.\n\nThe code reads two input texts, extracts keywords from each, and computes the similarity score between the two keyword lists. The final output is the similarity score printed to the console.",
                "content": "import nltk\nimport gensim.downloader\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nimport warnings\n\ninput_text1 = \"\"\"\nI want to modify the maxProfit function to have an initial maxP value of 10\n\"\"\"\n\ninput_text2 = \"\"\"\nThe maxProfit function is part of a C++ class Solution. It calculates the maximum profit that can be made from a list of stock prices (prices). The function follows these steps:\n\nInitialize Profit: It initializes maxP, the maximum profit, to 0.\nIterate Through Prices: It loops through the list of prices from the second element (index 1) to the end.\nCalculate Profit: If the current price is higher than the previous price, it calculates the profit by subtracting the previous price from the current price and adds it to maxP.\nReturn Profit: The function returns the accumulated maxP as the maximum profit.\nOverall, this function implements a simple algorithm for finding the total profit from multiple price increases in a stock price list, where each increase represents a buy-and-sell opportunity.\n\"\"\"\n\n#######################extract keywords#######################\n\n#download necessary resources\n# nltk.download('averaged_perceptron_tagger')\n# nltk.download(\"punkt\")\n# nltk.download(\"stopwords\")\n\ndef extract_keywords(text):\n    #tokenize the text into words\n    tokens = word_tokenize(text)\n    #define a set of common English stopwords\n    stop_words = set(stopwords.words(\"english\"))\n    #filter out stopwords and keep significant words(i.e. nouns, verbs)\n    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n    keywords = []\n    #identify keywords using part-of-speech tagging\n    pos_tags = nltk.pos_tag(filtered_tokens)\n    #keep only nouns, proper nouns, and verbs\n    for word, pos in pos_tags:\n        if pos.startswith(\"NN\") or pos.startswith(\"VB\"):\n            keywords.append(word)\n    unique_keywords = list(set(keywords))\n    return unique_keywords\n\n# print(extract_keywords(input_text1))\n\n#######################compute the similarity between keywords#######################\n\nwarnings.filterwarnings(action='ignore')\n#  Reads \u2018context.txt\u2019 file (for our application this will be the aggrgated summary report for a code file)\nsample = open(\"/Users/trav/Documents/projects/codesense/keyword_extraction/context.txt\")\ns = sample.read()\n# Replaces escape character with space\nf = s.replace(\"\\n\", \" \")\ndata = []\n# iterate through each sentence in the file\nfor i in sent_tokenize(f):\n    temp = []\n    # tokenize the sentence into words\n    for j in word_tokenize(i):\n        temp.append(j.lower())\n    data.append(temp)\nmodel = gensim.models.Word2Vec(data, min_count=1,\n                                vector_size=100, window=5, sg=1)\n\ndef compare_words(w1, w2):\n    if w1 == w2:\n        return 1\n    if w1 in model.wv and w2 in model.wv:\n        return model.wv.similarity(w1, w2)\n    else:\n        return 0\n\ndef compare_keywords(l1, l2):\n    output = 0\n    for word1 in l1:\n        word1 = word1.lower()\n        for word2 in l2:\n            output += compare_words(word1, word2.lower())\n    return output\n\nlist1 = extract_keywords(input_text1)\nlist2 = extract_keywords(input_text2)\nprint(compare_keywords(list1, list2))\n"
            }
        },
        {
            "score": 0.5,
            "matched_keywords": [
                "python",
                "testkeywordextract",
                "nltk"
            ],
            "node": {
                "name": "keyword_extract.py",
                "type": "file",
                "keywords": [
                    "English",
                    "Language",
                    "Natural",
                    "Python",
                    "TestKeywordExtract",
                    "Toolkit",
                    "annotated",
                    "based",
                    "class",
                    "code",
                    "contains",
                    "create",
                    "description",
                    "ensuring",
                    "expected",
                    "extracted",
                    "extraction",
                    "extracts",
                    "filtering",
                    "filters",
                    "identifies",
                    "includes",
                    "input",
                    "keyword",
                    "keywords",
                    "list",
                    "lists",
                    "method",
                    "nltk",
                    "nouns",
                    "output",
                    "pieces",
                    "processing",
                    "provided",
                    "query",
                    "running",
                    "script",
                    "selecting",
                    "stopwords",
                    "tagging",
                    "test",
                    "text",
                    "tokenizes",
                    "written"
                ],
                "annotation": "The code is written in Python and utilizes the Natural Language Toolkit (nltk) library to create a class that extracts keywords from text by processing and filtering out common English stopwords, then selecting only nouns and verbs. The `KeywordExtract` class contains an `extract` method which tokenizes the input text, filters out stopwords, and identifies keywords based on part-of-speech tagging. A secondary class, `TestKeywordExtract`, is provided to test the keyword extraction on specific pieces of text, ensuring the output is a list of relevant keywords. The expected output of running the main script includes printed lists of keywords extracted from a user query and an annotated code description.",
                "content": "import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n\n'''\nCreate a class to extract keywords from text\n- input:\n    - sample text as a string\n-output: \n    - list of keywords\n'''\n\n\nclass KeywordExtract:\n    def __init__(self):\n        self.keywords = []\n        # common english stopwords\n        self.stop_words = set(stopwords.words(\"english\"))\n\n    def extract(self, text):\n        tokens = word_tokenize(text)  # tokenize text\n        filtered_tokens = [word for word in tokens if word.lower(\n        ) not in self.stop_words]  # filter out stopwords\n        # identify keywords with part of speech tagging\n        pos_tags = nltk.pos_tag(filtered_tokens)\n        # keep only nouns, verbs\n        for word, pos in pos_tags:\n            if pos.startswith(\"NN\") or pos.startswith(\"VB\"):\n                self.keywords.append(word)\n        self.keywords = list(set(self.keywords))  # remove duplicates\n        return self.keywords\n\n\nclass TestKeywordExtract:\n    def __init__(self):\n        self.extractor = KeywordExtract()\n        print(\"Testing Keyword Extractor...\\n\")\n\n    def test_extract_keywords_from_query(self):\n        print(\"Testing keywword extraction of user query...\\n\")\n        text = \"I want to modify the maxProfit function to have an initial maxP value of 10\"\n        output = self.extractor.extract(text)\n        print(f\"Keywords from query: {output}\\n\")\n        assert type(output) == list\n\n    def test_extract_keywords_from_annotation(self):\n        print(\"Testing keywword extraction of code annotation...\\n\")\n        text = \"\"\"\n            The maxProfit function is part of a C++ class Solution. It calculates the maximum profit that can be made from a list of stock prices (prices). The function follows these steps:\n\n            Initialize Profit: It initializes maxP, the maximum profit, to 0.\n            Iterate Through Prices: It loops through the list of prices from the second element (index 1) to the end.\n            Calculate Profit: If the current price is higher than the previous price, it calculates the profit by subtracting the previous price from the current price and adds it to maxP.\n            Return Profit: The function returns the accumulated maxP as the maximum profit.\n            Overall, this function implements a simple algorithm for finding the total profit from multiple price increases in a stock price list, where each increase represents a buy-and-sell opportunity.\n            \"\"\"\n        output = self.extractor.extract(text)\n        print(f\"Keywords from annotation: {output}\\n\")\n        assert type(output) == list\n\n\nif __name__ == \"__main__\":\n    testKeywordExtract = TestKeywordExtract()\n    testKeywordExtract.test_extract_keywords_from_query()\n    testKeywordExtract.test_extract_keywords_from_annotation()\n"
            }
        },
        {
            "score": 0.3333333333333333,
            "matched_keywords": [
                "python",
                "nltk"
            ],
            "node": {
                "name": "info.txt",
                "type": "file",
                "keywords": [
                    "Automatic",
                    "Extraction",
                    "Gensim",
                    "Keyword",
                    "NLP",
                    "NLTK",
                    "Python",
                    "RAKE",
                    "Rapid",
                    "SSL",
                    "algorithm",
                    "certificate",
                    "changing",
                    "command",
                    "commands",
                    "consists",
                    "downloading",
                    "downloads",
                    "environment",
                    "error",
                    "gensim",
                    "install",
                    "installing",
                    "instructs",
                    "involves",
                    "issue",
                    "language",
                    "model",
                    "occurs",
                    "packages",
                    "processing",
                    "provided",
                    "setting",
                    "shell",
                    "suggests",
                    "text",
                    "tokenization",
                    "use",
                    "version",
                    "words"
                ],
                "annotation": "The provided text consists of shell commands primarily for setting up a natural language processing (NLP) environment in Python. It involves installing the RAKE (Rapid Automatic Keyword Extraction) algorithm via `pip3 install --user rake-nltk` and downloading necessary NLTK packages for tokenization and stop words. If an SSL certificate error occurs during the downloads, it instructs changing the Python version in a specific command to fix the issue. Finally, it suggests installing the Gensim library with `pip3 install gensim` to use the Word2Vec model.",
                "content": "install RAKE\n`pip3 install --user rake-nltk`\n\ninstall supporting nltk packages\n`python3 -c \"import nltk; nltk.download('punkt'); nltk.download('stopwords')\"`\n\nif you get a ssl certificate error run following command (change python version to which ever one you're running). Then rerun the above command\n\n`bash '/Applications/Python 3.9/Install Certificates.command'`\n\nto use word2vec install gensim library\n`pip3 install gensim`\n\n\n\n\n\n"
            }
        }
    ]
}